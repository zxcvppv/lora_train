{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Led8SgZ0YnGB",
        "pYZtXvtmes2I",
        "bSug2SNMq9Hg"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxcvppv/lora_train/blob/main/%E2%80%9Ckohya_train_webui_ipynb%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=wsh.kohya_train_webui)\n",
        "[![Visitors](https://api.visitorbadge.io/api/combined?path=wsh.kohya_train_webui&countColor=%232ccce4&style=flat&labelStyle=none)](https://visitorbadge.io/status?path=wsh.kohya_train_webui)\n",
        "[![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/kohya-config-webui?style=social)](https://github.com/WSH032/kohya-config-webui)\n",
        "\n",
        "| Notebook Name | Description | Link | Old-Version |\n",
        "| --- | --- | --- | --- |\n",
        "| [Colab_Lora_train](https://github.com/WSH032/lora-scripts/) | 基于[Akegarasu/lora-scripts](https://github.com/Akegarasu/lora-scripts)的定制化Colab notebook | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/WSH032/lora-scripts/blob/main/Colab_Lora_train.ipynb) | [![](https://img.shields.io/static/v1?message=Older%20Version&logo=googlecolab&labelColor=5c5c5c&color=e74c3c&label=%20&style=flat)](https://colab.research.google.com/drive/1_f0qJdM43BSssNJWtgjIlk9DkIzLPadx) |\n",
        "| [kohya_train_webui](https://github.com/WSH032/kohya-config-webui) `NEW` | 基于[WSH032/kohya-config-webui](https://github.com/WSH032/kohya-config-webui)的WebUI版Colab notebook | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/WSH032/kohya-config-webui/blob/main/kohya_train_webui.ipynb) |\n",
        "\n",
        "如果你觉得此项目有用，可以去 [![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/kohya-config-webui?style=social)](https://github.com/WSH032/kohya-config-webui)</a>  点一颗小星星，非常感谢你⭐\n",
        "\n",
        "---\n",
        "\n",
        "- [📚notebook的操作手册](https://www.bilibili.com/read/cv23401664)\n",
        "\n",
        "- 参数：\n",
        "\n",
        " - [🥶冷门而有用的参数](https://www.bilibili.com/video/BV1mo4y1t7Zu/)\n",
        " - [🆕新版参数](https://www.bilibili.com/video/BV13s4y1377X/)\n",
        "\n",
        "---\n",
        "\n",
        "Based on the work of [kohya-ss](https://github.com/kohya-ss/sd-scripts) and [Linaqruf](https://github.com/Linaqruf/kohya-trainer)\n",
        "\n",
        "WebUI from [WSH032](https://github.com/WSH032/kohya-config-webui)\n"
      ],
      "metadata": {
        "id": "ll6PRAEKIfjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 更新日志\n",
        "\n",
        "> 2023年5月24日：适配colab的torch==2.0.1\n",
        ">\n",
        "> 内容：适合torch==2.0.1的xformer以发布，不再强制安装torch==2.0.0，依赖安装时间恢复至2分40秒\n"
      ],
      "metadata": {
        "id": "TO3SVJYKmQhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （一）环境配置"
      ],
      "metadata": {
        "id": "Led8SgZ0YnGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##初始化常量与挂载谷歌硬盘（只要重启过colab就要再运行一次）\n",
        "\n",
        "#@markdown 是否挂载谷歌硬盘（推荐）\n",
        "use_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "ROOT_DIR = os.getcwd()    #获取根目录\n",
        "\n",
        "SD_SCRIPTS_DIR = os.path.join( ROOT_DIR, \"sd-scripts\" )    #kohya库克隆路径\n",
        "WEBUI_DIR = os.path.join( ROOT_DIR, \"kohya-config-webui\" )   #webui库克隆路径\n",
        "\n",
        "#TRAIN_DATA_DIR = os.path.join( ROOT_DIR, \"Lora\", \"input\" )    #拷贝后训练材料路径\n",
        "#REG_DATA_DIR = os.path.join( ROOT_DIR, \"Lora\", \"reg\" )   #拷贝后正则化材料路径\n",
        "\n",
        "SD_MODEL_DIR = os.path.join( ROOT_DIR, \"Lora\", \"sd_model\" )    #SD模型下载地址\n",
        "VAE_MODEL_DIR = os.path.join( ROOT_DIR, \"Lora\", \"vae_model\" )    #VAE模型下载地址\n",
        "\n",
        "DEFAULT_COLAB_INPUT_DIR = os.path.normpath(\"/content/drive/MyDrive/Lora/input\")    #默认Colab训练集地址\n",
        "DEFAULT_COLAB_REG_DIR = os.path.normpath(\"/content/drive/MyDrive/Lora/reg\")    #默认Colab正则化地址\n",
        "DEFAULT_COLAB_OUPUT_DIR = os.path.normpath(\"/content/drive/MyDrive/Lora/output\")    #默认Colab模型输出地址\n",
        "DEFAULT_COLAB_WEBUI_SAVE_DIR = os.path.normpath(\"/content/drive/MyDrive/Lora/kohya_config_webui_save\")    #默认Colab保存webui参数文件地址\n",
        "\n",
        "ACCELERATE_CONFIG_PATH = os.path.join( ROOT_DIR, \"accelerate_config.yaml\" )   #accelerate库config文件写入地址\n",
        "\n",
        "\n",
        "#@title ##挂载谷歌硬盘\n",
        "\n",
        "if use_google_drive:\n",
        "    if not os.path.exists(\"/content/drive\"):\n",
        "        drive.mount(\"/content/drive\")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "#训练用环境变量\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\""
      ],
      "metadata": {
        "id": "lcFMoxnjwCDV",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6ef48e-c34d-4d49-e6be-a03a187684ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mon Sep 11 04:52:39 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##克隆github的库、安装依赖\n",
        "os.chdir( ROOT_DIR )\n",
        "!git clone https://github.com/kohya-ss/sd-scripts.git {SD_SCRIPTS_DIR}\n",
        "#@title 克隆我的库\n",
        "!git clone https://github.com/WSH032/kohya-config-webui.git {WEBUI_DIR}\n",
        "\n",
        "#安装torch\n",
        "print(f\"torch安装中\")\n",
        "!pip -q install torch torchvision xformers triton\n",
        "print(f\"torch安装完成\")\n",
        "\n",
        "#安装kohya依赖\n",
        "print(f\"kohya依赖安装中\")\n",
        "os.chdir(SD_SCRIPTS_DIR)\n",
        "!pip -q install -r requirements.txt\n",
        "os.chdir(ROOT_DIR)\n",
        "print(f\"kohya依赖安装完成\")\n",
        "\n",
        "#安装lion优化器、Dadaption优化器、lycoris\n",
        "print(f\"lion优化器、Dadaption优化器、lycoris安装中\")\n",
        "!pip -q install --upgrade lion-pytorch dadaptation lycoris-lora\n",
        "print(f\"lion优化器、Dadaption优化器、lycoris安装完成\")\n",
        "\n",
        "#安装wandb\n",
        "print(f\"wandb安装中\")\n",
        "!pip -q install wandb\n",
        "print(f\"wandb安装中\")\n",
        "\n",
        "#安装webui依赖\n",
        "print(f\"webui依赖安装中\")\n",
        "os.chdir(WEBUI_DIR)\n",
        "!pip -q install -r requirements.txt\n",
        "os.chdir(ROOT_DIR)\n",
        "print(f\"webui依赖安装完成\")\n",
        "\n",
        "#安装功能性依赖\n",
        "!apt -q install aria2\n",
        "!pip -q install portpicker\n",
        "\n",
        "\n",
        "import torch\n",
        "print(\"当前torch版本\",torch.__version__)\n",
        "import torchvision\n",
        "print(\"当前torchvision版本\",torchvision.__version__)\n",
        "import triton\n",
        "print(\"当前triton版本\", triton.__version__)\n",
        "\n",
        "!python -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4wYnLUrYY6Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a56d65-9ffa-4263-f1b7-d4fab7bafc03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/sd-scripts'...\n",
            "remote: Enumerating objects: 4239, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 4239 (delta 180), reused 230 (delta 151), pack-reused 3959\u001b[K\n",
            "Receiving objects: 100% (4239/4239), 8.39 MiB | 13.32 MiB/s, done.\n",
            "Resolving deltas: 100% (2949/2949), done.\n",
            "Cloning into '/content/kohya-config-webui'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 129 (delta 7), reused 0 (delta 0), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (129/129), 76.97 KiB | 1.22 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "torch安装中\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htorch安装完成\n",
            "kohya依赖安装中\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "yfinance 0.2.28 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mkohya依赖安装完成\n",
            "lion优化器、Dadaption优化器、lycoris安装中\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "lion优化器、Dadaption优化器、lycoris安装完成\n",
            "wandb安装中\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "wandb安装中\n",
            "webui依赖安装中\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "webui依赖安装完成\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.2 [45.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Fetched 1,513 kB in 1s (2,082 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "当前torch版本 2.0.1+cu118\n",
            "当前torchvision版本 0.15.2+cu118\n",
            "当前triton版本 2.0.0\n",
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 下载模型, 可以同时选多个模型下载，到时候是在WebUI里选（原始代码来源于：[Linaqruf](https://github.com/Linaqruf/kohya-trainer)）\n",
        "installModels = []\n",
        "installv2Models = []\n",
        "\n",
        "#@markdown **预设底模**\n",
        "\n",
        "#@markdown SD1.x model\n",
        "modelName = \"Animefull-final-pruned.ckpt\"  # @param [\"\", \"Animefull-final-pruned.ckpt\", \"Anything-v3-1.safetensors\", \"AnyLoRA.safetensors\", \"AnimePastelDream.safetensors\", \"Chillout-mix.safetensors\", \"OpenJourney-v4.ckpt\", \"Stable-Diffusion-v1-5.safetensors\"]\n",
        "#@markdown SD2.x model `这些为SD2.x模型，训练时请开启v2选项`\n",
        "v2ModelName = \"\"  # @param [\"\", \"stable-diffusion-2-1-base.safetensors\", \"stable-diffusion-2-1-768v.safetensors\", \"plat-diffusion-v1-3-1.safetensors\", \"replicant-v1.safetensors\", \"illuminati-diffusion-v1-0.safetensors\", \"illuminati-diffusion-v1-1.safetensors\", \"waifu-diffusion-1-4-anime-e2.ckpt\", \"waifu-diffusion-1-5-e2.safetensors\", \"waifu-diffusion-1-5-e2-aesthetic.safetensors\"]\n",
        "\n",
        "#@markdown **自定义模型（不能超过5G）URL例如**`https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/novelailatest-pruned.ckpt`\n",
        "\n",
        "base_model_url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **或者自定义模型（不能超过5G）路径例如**`/content/drive/MyDrive/Lora/model/your_model.ckpt`\n",
        "\n",
        "base_model_self_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "def get_sd_model():\n",
        "    modelUrl = [\n",
        "        \"\",\n",
        "        \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "        \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "        \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\",\n",
        "        \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "        \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "        \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "        \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "    ]\n",
        "    modelList = [\n",
        "        \"\",\n",
        "        \"Animefull-final-pruned.ckpt\",\n",
        "        \"Anything-v3-1.safetensors\",\n",
        "        \"AnyLoRA.safetensors\",\n",
        "        \"AnimePastelDream.safetensors\",\n",
        "        \"Chillout-mix.safetensors\",\n",
        "        \"OpenJourney-v4.ckpt\",\n",
        "        \"Stable-Diffusion-v1-5.safetensors\",\n",
        "    ]\n",
        "    v2ModelUrl = [\n",
        "        \"\",\n",
        "        \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\",\n",
        "        \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n",
        "        \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\",\n",
        "        \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors\",\n",
        "        \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\",\n",
        "        \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n",
        "        \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\",\n",
        "        \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors\",\n",
        "        \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors\",\n",
        "    ]\n",
        "    v2ModelList = [\n",
        "        \"\",\n",
        "        \"stable-diffusion-2-1-base.safetensors\",\n",
        "        \"stable-diffusion-2-1-768v.safetensors\",\n",
        "        \"plat-diffusion-v1-3-1.safetensors\",\n",
        "        \"replicant-v1.safetensors\",\n",
        "        \"illuminati-diffusion-v1-0.safetensors\",\n",
        "        \"illuminati-diffusion-v1-1.safetensors\",\n",
        "        \"waifu-diffusion-1-4-anime-e2.ckpt\",\n",
        "        \"waifu-diffusion-1-5-e2.safetensors\",\n",
        "        \"waifu-diffusion-1-5-e2-aesthetic.safetensors\",\n",
        "    ]\n",
        "    if modelName:\n",
        "        installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "    if v2ModelName:\n",
        "        installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "\n",
        "    #下载模型\n",
        "    def install(checkpoint_name, url):\n",
        "        hf_token = \"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\"\n",
        "        user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "        print(checkpoint_name)\n",
        "        print(url)\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {SD_MODEL_DIR} -o {checkpoint_name} {url}\n",
        "    def install_checkpoint():\n",
        "        for model in installModels:\n",
        "            install(model[0], model[1])\n",
        "        for v2model in installv2Models:\n",
        "            install(v2model[0], v2model[1])\n",
        "\n",
        "    #下载预设模型\n",
        "    install_checkpoint()\n",
        "\n",
        "    #自定义链接不留空，则尝试下载\n",
        "    if base_model_url:\n",
        "        #!aria2c --content-disposition-default-utf8=true --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {SD_MODEL_DIR} {base_model_url}\n",
        "        !wget {base_model_url} -P {SD_MODEL_DIR} -N\n",
        "\n",
        "    #自定义路径不留空，则尝试拷贝\n",
        "    if base_model_self_path:\n",
        "        try:\n",
        "            base_model_copy_path = os.path.join( SD_MODEL_DIR, os.path.basename(base_model_self_path) )\n",
        "            shutil.copyfile(base_model_self_path, base_model_copy_path)\n",
        "            print(f\"拷贝自定义底模成功, {base_model_self_path}被拷贝至{base_model_copy_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"拷贝自定义底模时发生错误， Error: {e}\")\n",
        "\n",
        "get_sd_model()\n",
        "\n",
        "\n",
        "#@markdown **(可选)选择一个Vae下载**`\"animevae.pt\", \"kl-f8-anime.ckpt\", \"vae-ft-mse-840000-ema-pruned.ckpt\"`\n",
        "\n",
        "vaeName = \"\"  # @param [\"\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "def get_vae_model():\n",
        "\n",
        "    installVae = []\n",
        "\n",
        "    vaeUrl = [\n",
        "        \"\",\n",
        "        \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "        \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "        \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "    ]\n",
        "    vaeList = [\"\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "    installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "    #开始下载\n",
        "    def install(vae_name, url):\n",
        "        hf_token = \"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\"\n",
        "        user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "        print(vae_name)\n",
        "        print(url)\n",
        "        !aria2c --console-log-level=error --allow-overwrite --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {VAE_MODEL_DIR} -o {vae_name} \"{url}\"\n",
        "\n",
        "    def install_vae():\n",
        "        if vaeName:\n",
        "            for vae in installVae:\n",
        "                install(vae[0], vae[1])\n",
        "        else:\n",
        "            pass\n",
        "    install_vae()\n",
        "\n",
        "get_vae_model()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OYGUN309MuUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （二）训练参数"
      ],
      "metadata": {
        "id": "pYZtXvtmes2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##启动WebUI来设置参数\n",
        "\n",
        "#@markdown - 在谷歌硬盘的`/content/drive/MyDrive/Lora/kohya_config_webui_save`会生成一个`colab.toml`，在WebUI里读取它，会帮你完成默认参数设置。\n",
        "#@markdown  - 读取的时候会提示参数找不到，这是正常的\n",
        "#@markdown - 设置好参数后可以保存`（默认会保存到你的谷歌硬盘）`，以后读取你保存的配置文件就行\n",
        "#@markdown  - 保存toml配置文件时候不要用`colab.toml`这个名字，会被覆盖掉\n",
        "\n",
        "#@markdown - 在colab里要开`lowram`，不然很多模型载入不了，读取`colab.toml`的时候会自动帮你开启\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown 是否在colab里打开webui`不勾选就输出一个链接，点击后在另一个网页操作，反正我喜欢不勾选`\n",
        "in_colab = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown 是否使用gradio的远程分享及队列功能\n",
        "use_queue = False #@param {type:\"boolean\"}\n",
        "\n",
        "#生成一个colab默认toml文件\n",
        "def creat_save_toml(save_dir):\n",
        "    \"\"\"生成适用于Colab的webui参数保存文件colab.toml\"\"\"\n",
        "    import toml\n",
        "    #写入路径\n",
        "    other={\"write_files_dir\":SD_SCRIPTS_DIR}\n",
        "    #材料、模型、输出路径\n",
        "    param={\n",
        "        \"train_data_dir\":DEFAULT_COLAB_INPUT_DIR,\n",
        "        \"reg_data_dir\":DEFAULT_COLAB_REG_DIR,\n",
        "        \"base_model_dir\":SD_MODEL_DIR,\n",
        "        \"vae_model_dir\":VAE_MODEL_DIR,\n",
        "        \"output_dir\":DEFAULT_COLAB_OUPUT_DIR,\n",
        "        \"lowram\":True,\n",
        "    }\n",
        "\n",
        "    save_dict = {\"other\":other, \"param\":param}\n",
        "    #写入文件\n",
        "    save_name = \"colab.toml\"\n",
        "    save_path = os.path.join( save_dir, save_name )\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write( toml.dumps(save_dict) )\n",
        "\n",
        "creat_save_toml(DEFAULT_COLAB_WEBUI_SAVE_DIR)\n",
        "\n",
        "#导入并生成demo\n",
        "launch_param = [f\"--save_dir={DEFAULT_COLAB_WEBUI_SAVE_DIR}\",\n",
        "        f\"--save_name=kohya_config_webui_save.toml\",\n",
        "        f\"--read_dir={DEFAULT_COLAB_WEBUI_SAVE_DIR}\"\n",
        "]\n",
        "os.chdir( os.path.join(WEBUI_DIR, \"module\") )\n",
        "from kohya_config_webui import create_demo\n",
        "os.chdir(ROOT_DIR)\n",
        "demo = create_demo(launch_param)\n",
        "\n",
        "#找一个空闲端口\n",
        "import portpicker\n",
        "port = portpicker.pick_unused_port()\n",
        "#启动\n",
        "if not use_queue:\n",
        "    demo.launch(server_port=port, inbrowser=False, inline=False)\n",
        "    #暴露端口\n",
        "    from google.colab import output\n",
        "    output.serve_kernel_port_as_window(port)\n",
        "    #是否在Colab里打开\n",
        "    if in_colab:\n",
        "        output.serve_kernel_port_as_iframe(port)\n",
        "else:\n",
        "    demo.queue().launch(server_port=port, inline=in_colab)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AlRW5ufPM-0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f5c9e611-a007-49ad-f2be-21f561802ff5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(44175, \"/\", \"https://localhost:44175/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  ### 开始训练\n",
        "\n",
        "#@markdown 若正确运行，训练完成后，模型会自动保存至你在WebUI里设置的地址\n",
        "\n",
        "#@markdown 默认训练配置文件在 `/content/sd-scripts/config_file.toml`\n",
        "\n",
        "#@markdown 默认采样参数文件在 `/content/sd-scripts/sample_prompts.txt`\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown 如果你想用自己的配置文件，或者采样文件，请填入下方 `填入意味着启用`\n",
        "\n",
        "config_file_self_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "sample_prompts_self_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "os.chdir(ROOT_DIR)\n",
        "\n",
        "from accelerate.utils import write_basic_config\n",
        "if not os.path.exists(ACCELERATE_CONFIG_PATH):\n",
        "    write_basic_config(save_location=ACCELERATE_CONFIG_PATH)\n",
        "\n",
        "\n",
        "\n",
        "os.chdir(SD_SCRIPTS_DIR)\n",
        "\n",
        "#开始训练！\n",
        "!accelerate launch --config_file={ACCELERATE_CONFIG_PATH} --num_cpu_threads_per_process=8 train_network.py\\\n",
        "  --config_file={config_file_self_path if config_file_self_path else \"config_file.toml\"}\\\n",
        "  --sample_prompts={sample_prompts_self_path if sample_prompts_self_path else \"sample_prompts.txt\"}\n",
        "\n",
        "os.chdir(ROOT_DIR)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NTRgMI7jR3DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （三）开发代码`别碰`"
      ],
      "metadata": {
        "id": "bSug2SNMq9Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title linaqfuf优化代码\n",
        "\n",
        "!sed -i \"s@cpu@cuda@\" /content/sd-scripts/library/model_util.py\n",
        "\n",
        "import zipfile\n",
        "def ubuntu_deps(url, name, dst):\n",
        "    !wget --show-progress {url}\n",
        "    with zipfile.ZipFile(name, \"r\") as deps:\n",
        "        deps.extractall(dst)\n",
        "    !dpkg -i {dst}/*\n",
        "    os.remove(name)\n",
        "    shutil.rmtree(dst)\n",
        "deps_dir = \"/conent/dep\"\n",
        "ubuntu_deps(\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\",\n",
        "    \"deb-libs.zip\",\n",
        "    deps_dir,\n",
        ")\n",
        "\n",
        "!apt -y update\n",
        "!apt install libunwind8-dev\n",
        "\n",
        "os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "cuda_path = \"/usr/local/cuda-11.8/targets/x86_64-linux/lib/\"\n",
        "ld_library_path = os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "os.environ[\"LD_LIBRARY_PATH\"] = f\"{ld_library_path}:{cuda_path}\""
      ],
      "metadata": {
        "id": "ps6GgFwVaqXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##拷贝材料(支持重复训练时选择新的路径)\n",
        "\n",
        "#@markdown 训练集路径，正则化集路径(正则化留空则不拷贝)\n",
        "\n",
        "#@markdown `教程默认路径：`\n",
        "\n",
        "#@markdown `训练集：/content/drive/MyDrive/Lora/input/`\n",
        "\n",
        "#@markdown `正则化：/content/drive/MyDrive/Lora/reg/`\n",
        "\n",
        "train_data_dir_self = \"/content/drive/MyDrive/Lora/input/blue_archive\" #@param {type:'string'}\n",
        "reg_data_dir_self = \"\" #@param {type:'string'}\n",
        "\n",
        "\n",
        "def copy_data_and_reg(data_dir: str, reg_dir: str = \"\"):\n",
        "    \"\"\"\n",
        "    将材料拷贝至TRAIN_DATA_DIR和REG_DATA_DIR\n",
        "    拷贝前会删除之前材料\n",
        "    data_dir为训练集，必填； reg_dir，默认为空，不填则不拷贝\n",
        "    \"\"\"\n",
        "    #训练集路径为空直接退出\n",
        "    if not data_dir:\n",
        "        print(f\"训练集路径为空\")\n",
        "        return\n",
        "\n",
        "    #已经存在拷贝材料则删除\n",
        "    def rm_dir(dir):\n",
        "        if os.path.exists(dir):\n",
        "            shutil.rmtree(dir)\n",
        "    rm_dir(TRAIN_DATA_DIR)\n",
        "    rm_dir(REG_DATA_DIR)\n",
        "\n",
        "    #拷贝材料\n",
        "    def cp_dir(from_dir, to_dir, name):\n",
        "        print(f\"拷贝{name}中\")\n",
        "        try:\n",
        "            shutil.copytree(from_dir, to_dir, dirs_exist_ok=True)\n",
        "            print(f\"{name}拷贝成功, {from_dir}被拷贝至{to_dir}\")\n",
        "        except Exception as e:\n",
        "            print(f\"拷贝{name}时发生错误， Error: {e}\")\n",
        "\n",
        "    cp_dir(data_dir, TRAIN_DATA_DIR, \"训练集\")\n",
        "    if reg_dir:\n",
        "        cp_dir(reg_dir, REG_DATA_DIR, \"训练集\")\n",
        "    else:\n",
        "        print(f\"不拷贝正则化\")\n",
        "\n",
        "copy_data_and_reg(train_data_dir_self, reg_data_dir_self)\n"
      ],
      "metadata": {
        "id": "EzHADOPZMlN4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}