{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W9wqv5U3iVZq",
        "19nEZDbHMzsv",
        "g8uAVOwb4wd8",
        "AyqSNCvqO1OB",
        "EP59EDzIH3AL",
        "GQ7GziwME6Fi"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxcvppv/lora_train/blob/main/%E2%80%9CColab_Lora_train_ipynb%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=wsh.colob_lora_train)\n",
        "[![Visitors](https://api.visitorbadge.io/api/combined?path=wsh.colob_lora_train&countColor=%232ccce4&style=flat&labelStyle=none)](https://visitorbadge.io/status?path=wsh.colob_lora_train)\n",
        "[![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/lora-scripts?style=social)](https://github.com/WSH032/lora-scripts/)\n",
        "\n",
        "| Notebook Name | Description | Link | Old-Version |\n",
        "| --- | --- | --- | --- |\n",
        "| [Colab_Lora_train](https://github.com/WSH032/lora-scripts/) | 基于[Akegarasu/lora-scripts](https://github.com/Akegarasu/lora-scripts)的定制化Colab notebook | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/WSH032/lora-scripts/blob/main/Colab_Lora_train.ipynb) | [![](https://img.shields.io/static/v1?message=Older%20Version&logo=googlecolab&labelColor=5c5c5c&color=e74c3c&label=%20&style=flat)](https://colab.research.google.com/drive/1_f0qJdM43BSssNJWtgjIlk9DkIzLPadx) |\n",
        "| [kohya_train_webui](https://github.com/WSH032/kohya-config-webui) `NEW` | 基于[WSH032/kohya-config-webui](https://github.com/WSH032/kohya-config-webui)的WebUI版Colab notebook | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/WSH032/kohya-config-webui/blob/main/kohya_train_webui.ipynb) |\n",
        "\n",
        "如果你觉得此项目有用，可以去[![GitHub Repo stars](https://img.shields.io/github/stars/WSH032/lora-scripts?style=social)](https://github.com/WSH032/lora-scripts/)</a> 点一颗小星星，非常感谢你⭐\n",
        "\n",
        "---\n",
        "\n",
        "# **基于：[秋葉aaaki](https://space.bilibili.com/12566101)发布的[保姆式LoRA模型一键包文件](https://www.bilibili.com/video/BV1fs4y1x7p2/)**\n",
        "\n",
        "1.   [保姆式LoRA模型一键包文件](https://www.bilibili.com/video/BV1fs4y1x7p2/)\n",
        "2.   [参数心得](https://www.bilibili.com/video/BV1GM411E7vk/)\n",
        "3.   [训练教程](https://www.bilibili.com/read/cv21926598)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> 修改by[Happy_WSH](https://space.bilibili.com/8417436)。"
      ],
      "metadata": {
        "id": "2xPpy2V_bm6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最新更新\n",
        "> **2023年5月24日**更新：colab更新\n",
        ">\n",
        "> 内容：\n",
        ">\n",
        "> - 更新torch==2.0.1 xformer==0.0.20\n",
        ">\n",
        "> - 更换新的访客计数器\n"
      ],
      "metadata": {
        "id": "4NJczBMrdbEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A. 训练前准备：**"
      ],
      "metadata": {
        "id": "k-OOv-mDlY8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **训练前准备（这只是教程，不是代码块，不需要你运行）：**\n",
        "#@markdown\n",
        "#@markdown **注意** 按下文步骤运行\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown > **使用前强烈建议观看[参数心得](https://www.bilibili.com/video/BV1GM411E7vk/)和[保姆式LoRA模型一键包文件](https://www.bilibili.com/video/BV1fs4y1x7p2/)视频内详细讲解了各参数的修改。**\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown > 提醒：Colab免费用户最长连续使用GPU时间不超过12h，不要搞过于大的训练文件，一旦被强制下线训练将会终止！\n",
        "#@markdown >\n",
        "#@markdown >\n",
        "#@markdown >  长时间训练的建议：\n",
        "#@markdown >\n",
        "#@markdown >1.   使用Up推荐的云平台训练[AutoDL](https://www.bilibili.com/read/cv21450198)\n",
        "#@markdown >2.   按 （七）、2  修改模型的输出路径更改至你的谷歌硬盘\n",
        "#@markdown\n",
        "#@markdown **推荐使用谷歌硬盘配合训练，如果你因为谷歌账号等问题无法挂载，请看文末教程**\n",
        "#@markdown > 谷歌硬盘点左上角那个*CO*图标\n",
        "#@markdown\n",
        "#@markdown ##**（一）首先打开谷歌硬盘（左上角那个*CO*图标）**\n",
        "#@markdown\n",
        "#@markdown 在你的谷歌硬盘根目录下新建一个文件夹命名为*Lora*，并在该文件夹中再次新建一个文件夹命名为*input*。\n",
        "#@markdown\n",
        "#@markdown **注意Lora首字母大写**\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown > 即  *我的云端硬盘/Lora/input/*\n",
        "#@markdown\n",
        "#@markdown ##**（二）**\n",
        "#@markdown\n",
        "#@markdown 按照视频中的要求处理完图并放置在命名好的文件夹的中，\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown > 即  *x_概念tag/处理后的图片*\n",
        "#@markdown\n",
        "#@markdown 和视频讲解一样，可以有多有*x_概念tag*文件夹。\n",
        "#@markdown\n",
        "#@markdown ##**（三）**\n",
        "#@markdown\n",
        "#@markdown 将这些*x_概念文件夹*上传到你的谷歌硬盘/Lora/input/目录下\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown > 即最后的结构是  *我的云端硬盘/Lora/input/x_概念tag/处理后的图片*\n",
        "#@markdown\n",
        "#@markdown **如果你要使用正则化图片，请参考图片放置在reg目录**\n",
        "#@markdown\n",
        "#@markdown ![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HP5TpWB6IHL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **B. 开始训练**"
      ],
      "metadata": {
        "id": "RBYsZ0r-EmPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##（四）挂载谷歌硬盘、拷贝秋叶的github"
      ],
      "metadata": {
        "id": "33G_QxFnGAJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 4.1 查看GPU信息**（确保你用的是GPU运行时）**、挂载谷歌硬盘（建议）\n",
        "\n",
        "#@markdown >**注意，如果这一步你挂载谷歌硬盘失败了。请看文末教程**\n",
        "#@markdown >\n",
        "#@markdown > 同时也需要注意，这意味着你的输出模型不会被保存到谷歌硬盘，而是临时存储在Colab的工作环境中，只要Colab一重启就会删除所有文件。**也就是说你要及时的手动保存输出模型**，请打开左边栏的文件选项，模型会被保存至/content/drive/MyDrive/Lora/output/，右键下载你的输出模型。\n",
        "\n",
        "#@markdown 如果你成功挂载了你的谷歌硬盘，则训练完成后数据会被保存到谷歌硬盘长期储存，而不会被自动清除。\n",
        "\n",
        "#查看是什么GPU\n",
        "!nvidia-smi\n",
        "#挂载谷歌硬盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!echo \"google硬盘挂载完成.\""
      ],
      "metadata": {
        "id": "vWy1hoUU3bv-",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0051d0-4243-4e53-9a6c-599cb6ebccd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 11 02:56:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Mounted at /content/drive/\n",
            "google硬盘挂载完成.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 4.2 克隆github中的lora训练模型、定义正则表达式函数、声明ExtArgsContent类用于在（六、七）中修改extArgs的值、初始化output、log、sample_prompt.txt、训练材料路径**（必须运行）**\n",
        "\n",
        "#@markdown **此代码块执行完后，lora训练文件会从相应的github克隆过来，你可以在安装依赖时去配置train.sh文件**\n",
        "\n",
        "#@markdown **中途切换版本会初始化除5.2的全部模块，如果你这么做了，请重复从5.4开始的拷贝、模型下载、参数配置**\n",
        "\n",
        "\n",
        "#@markdown 选择版本(我的备份版本、兼容python3.8的老版本)\n",
        "\n",
        "#@markdown - 不再默认提供秋叶版本(你下载最新的秋叶版本，可能会不兼容)\n",
        "\n",
        "#@markdown 秋叶更新后，如果我没第一时间做适配，出现bug或者报错，可以暂时使用我的备份版本\n",
        "\n",
        "choose_version = \"WSH\" #@param [\"WSH\", \"Akegarasu\", \"py3.8\"]\n",
        "\n",
        "###################################################################################\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "#删除先前下载的lora训练模型\n",
        "!mkdir -p /content/lora-scripts/  #防止报错\n",
        "!rm -r /content/lora-scripts/\n",
        "#选择github库\n",
        "if choose_version == \"Akegarasu\":\n",
        "  git_https = \"https://github.com/Akegarasu/lora-scripts\"\n",
        "elif choose_version == \"WSH\":\n",
        "  git_https = \"https://github.com/WSH032/lora-scripts.git\"\n",
        "elif choose_version == \"py3.8\":\n",
        "  #这是一个2023年3月1日的备份源，可以让你使用兼容py3.8的lora训练\n",
        "  git_https = \"https://github.com/WSH032/temp.git\"\n",
        "else:\n",
        "  print(\"git选择出错\")\n",
        "#从git仓库下载Lora训练模型\n",
        "print(f\"{choose_version}的github克隆中\")\n",
        "!git clone --recurse-submodules {git_https}  /content/lora-scripts/\n",
        "!cd lora-scripts && git pull && git submodule update --init --recursive\n",
        "#对于py3.8的lora训练模型需要做一个移动\n",
        "if choose_version == \"py3.8\":\n",
        "  !mv /content/lora-scripts/lora-scripts/* /content/lora-scripts/\n",
        "  !rm -r /content/lora-scripts/lora-scripts\n",
        "print(f\"{choose_version}的github克隆完成 你可以在安装依赖时去配置train.sh文件\")\n",
        "\n",
        "\n",
        "###################################################################################\n",
        "#这是一个使用正则表达式匹配编辑文件的函数，用于在（七）中对train.sh的修改\n",
        "\n",
        "#导入正则表达式模块\n",
        "import re\n",
        "#########\n",
        "#设置train.sh文件路径，这个在函数中会被使用\n",
        "train_sh_path = r'/content/lora-scripts/train.sh'\n",
        "#########\n",
        "#定义函数，编辑train_sh_path路径的文件，为search的参数赋予值input\n",
        "#search为字符串，input可以为数值和字符串\n",
        "def search_input(search, input):\n",
        "  # 使用正则表达式进行替换\n",
        "  #匹配标志: 1匹配search=\"\" ， 2匹配search=5 ， 3专门专门匹配extArgs=()\n",
        "  search_type_flag = 0\n",
        "\n",
        "  #search不是字符串就报错\n",
        "  if not( isinstance(search, str) ):\n",
        "    return \"非字符串的'search'参数\"\n",
        "\n",
        "  #如果search输入的是\"\"，则专门匹配extArgs=()\n",
        "  if search == \"\":\n",
        "    search = \"extArgs\"\n",
        "    pattern = rf'^{search}=(\\(.*?\\))'\n",
        "    replace = rf'{search}=({input})'\n",
        "    search_type_flag = 3\n",
        "  else:\n",
        "    # 如果input是字符串类型，匹配search=\"\"\n",
        "    if isinstance(input, str):\n",
        "      #pattern = rf'{search}=(\".*?\")'\n",
        "      #replace = f\"{search}=\\\"{input}\\\"\"\n",
        "      pattern = rf'^{search}=(\".*?\")'\n",
        "      replace = rf'{search}=\"{input}\"'\n",
        "      search_type_flag = 1\n",
        "    # 如果input是数值类型，匹配search= （可以匹配小数、整数、科学计数）\n",
        "    elif isinstance(input, (int, float)):\n",
        "      pattern = rf'^{search}=([+-]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][+-]?\\d+)?)'\n",
        "      replace = rf'{search}={input}'\n",
        "      search_type_flag = 2\n",
        "    else: # 其他情况，就返回错误信息\n",
        "      return \"错误的匹配input\"\n",
        "\n",
        "  #使用with语句打开文件，并读取内容\n",
        "  with open(train_sh_path, 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "    re_get = re.findall(pattern, content, flags=re.MULTILINE|re.DOTALL)\n",
        "    #检查是否匹配到，匹配不到则报错并退出\n",
        "    if not(re_get):\n",
        "      print(f\"警告！！！对于'{search}'的正则表达式并未匹配，请手动设置该参数，并B站私信我更新！\")\n",
        "      return\n",
        "    #如果匹配到了执行接下来操作\n",
        "    #使用re.sub函数进行替换，并加上re.MULTILINE标志\n",
        "    new_content = re.sub(pattern, replace, content, flags=re.MULTILINE|re.DOTALL, count=1)\n",
        "    #如果内容未更改，提示未改变以及值\n",
        "    if new_content == content:\n",
        "      print(f\"{search}={re_get[0]}\")\n",
        "      return\n",
        "    #如果改变则写入，输出改变信息\n",
        "    else:\n",
        "      with open(train_sh_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(new_content)\n",
        "      if search_type_flag == 1: right = left = \"\\\"\"\n",
        "      elif search_type_flag == 2: right = left = \"\"\n",
        "      elif search_type_flag == 3: right = \")\" ; left = \"(\"\n",
        "      else: print(\"输入参数错误\")\n",
        "      print(f\"发生修改，{search}={re_get[0]}现在为{left}{input}{right}\")\n",
        "\n",
        "#模型输出地址被更改至\"/content/drive/MyDrive/Lora/output/\"\n",
        "output_dir = \"/content/drive/MyDrive/Lora/output/\"\n",
        "search_input(\"  --output_dir\", output_dir)\n",
        "print(f\"模型输出地址默认被更改至谷歌硬盘：{output_dir}\")\n",
        "\n",
        "#初始化log输出路径\n",
        "logging_dir = output_dir + \"/logs\"\n",
        "search_input(\"  --logging_dir\", logging_dir)\n",
        "print(f\"log日志默认输出至谷歌硬盘：{logging_dir}\")\n",
        "\n",
        "#初始化sample_prompt.txt路径\n",
        "sample_prompt_txt_path = \"/content/lora-scripts/sample_prompt.txt\"\n",
        "print(f\"sample_prompt.txt默认路径为：{sample_prompt_txt_path}\")\n",
        "\n",
        "#初始化训练集路径\n",
        "train_data_dir = \"/content/lora-scripts/train/aki/\"\n",
        "search_input(\"train_data_dir\", train_data_dir)\n",
        "print(f\"训练集将拷贝至：{train_data_dir}\")\n",
        "\n",
        "#初始化正则化集路径\n",
        "reg_data_dir = \"/content/lora-scripts/train/reg/\"\n",
        "print(f\"正则化集将拷贝至：{reg_data_dir}\")\n",
        "\n",
        "#弃用代码\n",
        "#!sed -i 's/--output_dir=\".\\/output\"/--output_dir=\"/content/drive/MyDrive/Lora/output/\"/' /content/lora-scripts/train.sh\n",
        "\n",
        "\n",
        "#################################################################\n",
        "#声明extArgs_Content类，用于在不同代码块中更新extArgs的内容\n",
        "class ExtArgsContent(object):\n",
        "  def __init__(self):\n",
        "    self.base_model = \"\"\n",
        "    self.vae = \"\"\n",
        "    self.common_parameter = \"\"\n",
        "    self.sample_parameter = \"\"\n",
        "    self.plus_parameter = \"\"\n",
        "  #合并全部类属性字符串\n",
        "  def all(self):\n",
        "    result = \"\"\n",
        "    attributes = self.__dict__.values()\n",
        "    for attribute in attributes:\n",
        "      result += attribute\n",
        "    return result\n",
        "#将在（六、七）中被使用\n",
        "extArgs_content = ExtArgsContent()\n",
        "\n",
        "#################################################################\n",
        "#用于读取  --output_dir=\"\"和  --logging_dir=\"\"的值，来修改8.2中保存路径\n",
        "def search_get(search):\n",
        "  # 如果input是字符串类型，匹配search=\"\"\n",
        "  #pattern = rf'{search}=(\".*?\")'\n",
        "  pattern = rf'^{search}=(\".*?\")'\n",
        "  #使用with语句打开文件，并读取内容\n",
        "  with open(train_sh_path, 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "    re_get = re.findall(pattern, content, flags=re.MULTILINE|re.DOTALL)\n",
        "    return re_get[0]\n",
        "\n",
        "#################################################################\n",
        "#初始化，在（八）中执行判断\n",
        "enable_sample = False\n",
        "use_train_sh_self = False\n",
        "use_sample_prompt_txt_self = False\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UV6qjXaZRLFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c348dbbf-1640-4f1b-80f6-2573c5bfcb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "WSH的github克隆中\n",
            "Cloning into '/content/lora-scripts'...\n",
            "remote: Enumerating objects: 486, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 486 (delta 247), reused 208 (delta 208), pack-reused 216\u001b[K\n",
            "Receiving objects: 100% (486/486), 319.73 KiB | 11.42 MiB/s, done.\n",
            "Resolving deltas: 100% (285/285), done.\n",
            "Submodule 'frontend' (https://github.com/hanamizuki-ai/lora-gui-dist) registered for path 'frontend'\n",
            "Submodule 'sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'sd-scripts'\n",
            "Cloning into '/content/lora-scripts/frontend'...\n",
            "remote: Enumerating objects: 719, done.        \n",
            "remote: Counting objects: 100% (719/719), done.        \n",
            "remote: Compressing objects: 100% (432/432), done.        \n",
            "remote: Total 719 (delta 377), reused 587 (delta 245), pack-reused 0        \n",
            "Receiving objects: 100% (719/719), 2.85 MiB | 17.06 MiB/s, done.\n",
            "Resolving deltas: 100% (377/377), done.\n",
            "Cloning into '/content/lora-scripts/sd-scripts'...\n",
            "remote: Enumerating objects: 4239, done.        \n",
            "remote: Counting objects: 100% (280/280), done.        \n",
            "remote: Compressing objects: 100% (119/119), done.        \n",
            "remote: Total 4239 (delta 180), reused 222 (delta 161), pack-reused 3959        \n",
            "Receiving objects: 100% (4239/4239), 8.28 MiB | 21.57 MiB/s, done.\n",
            "Resolving deltas: 100% (2954/2954), done.\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 68 (delta 26), reused 55 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), 441.68 KiB | 3.56 MiB/s, done.\n",
            "From https://github.com/hanamizuki-ai/lora-gui-dist\n",
            " * branch            4cccc348e8ff86e51dea1d0a3cf91f06c1d087ca -> FETCH_HEAD\n",
            "Submodule path 'frontend': checked out '4cccc348e8ff86e51dea1d0a3cf91f06c1d087ca'\n",
            "Submodule path 'sd-scripts': checked out 'd52c524fc2942c053cf37c648188502a3a26df1b'\n",
            "Already up to date.\n",
            "WSH的github克隆完成 你可以在安装依赖时去配置train.sh文件\n",
            "发生修改，  --output_dir=\"./output\"现在为\"/content/drive/MyDrive/Lora/output/\"\n",
            "模型输出地址默认被更改至谷歌硬盘：/content/drive/MyDrive/Lora/output/\n",
            "发生修改，  --logging_dir=\"./logs\"现在为\"/content/drive/MyDrive/Lora/output//logs\"\n",
            "log日志默认输出至谷歌硬盘：/content/drive/MyDrive/Lora/output//logs\n",
            "sample_prompt.txt默认路径为：/content/lora-scripts/sample_prompt.txt\n",
            "发生修改，train_data_dir=\"./train/aki\"现在为\"/content/lora-scripts/train/aki/\"\n",
            "训练集将拷贝至：/content/lora-scripts/train/aki/\n",
            "正则化集将拷贝至：/content/lora-scripts/train/reg/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## （五）、安装环境及拷贝材料"
      ],
      "metadata": {
        "id": "UIMsiQtyDAcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 5.1是否打开web文件浏览器，方便你管理Colab环境中的文件（可选）\n",
        "\n",
        "#@markdown 是否使用web文件浏览器,在你运行其他代码块的时候这也是实时工作的 *(在colab中使用，在新标签页使用)*\n",
        "use_file_explorer = True #@param {type:\"boolean\"}\n",
        "file_explorer_method = \"use in new tab\" #@param [\"use in colab\",\"use in new tab\"]\n",
        "\n",
        "\n",
        "\n",
        "if use_file_explorer:\n",
        "  #安装imjoy-elfinder（web文件浏览器）\n",
        "  !pip -q install imjoy-elfinder  > /dev/null 2>&1\n",
        "  import threading\n",
        "  from google.colab import output\n",
        "  from imjoy_elfinder.app import main\n",
        "  #开始imjoy-elfinder服务\n",
        "  thread = threading.Thread(target=main, args=[[\"--root-dir=/content\", \"--port=8765\"]])\n",
        "  thread.start()\n",
        "  if file_explorer_method == \"use in colab\":\n",
        "    #在colab中打开端口\n",
        "    output.serve_kernel_port_as_iframe(8765, height='600')\n",
        "  elif file_explorer_method == \"use in new tab\":\n",
        "    #在新标签页打开端口\n",
        "    output.serve_kernel_port_as_window(8765)\n",
        "  else:\n",
        "    print(\"imjoy_elfinder使用出错\")\n",
        "#提示未勾选\n",
        "else:\n",
        "  print(\"你似乎想使用web文件浏览器，但你并未勾选\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j8pnanXvL44g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55614f48-8d23-401c-dfa3-a382e316d6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8765, \"/\", \"https://localhost:8765/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 5.2 安装依赖环境、开启tensorboard**（输出已经被隐藏，有需要可以自己修改代码看输出）**\n",
        "\n",
        "#@markdown 整个环境安装所需时间为**2分钟左右**\n",
        "#@markdown\n",
        "#@markdown **在（四）中lora训练文件已经被克隆进来，如果你已经熟练使用此colab，你可以利用这段时间上传图片，或者去*（七）*完成train.sh的配置**\n",
        "#@markdown\n",
        "#@markdown train.sh文件: /content/lora-scripts/train.sh\n",
        "###################################################################################\n",
        "#升级python\n",
        "#感谢枫娘分享的代码\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "现在colab默认已经是python3.10\n",
        "install python 3.10 安装py3.10\n",
        "!sudo apt-get update -y > /dev/null 2>&1\n",
        "!sudo apt-get install python3.10 > /dev/null 2>&1\n",
        "#change alternatives 首选py3.9\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1  > /dev/null 2>&1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2  > /dev/null 2>&1\n",
        "#check python version 查看版本 #3.10\n",
        "!python --version\n",
        "print(\"python升级中\")\n",
        "# install pip for new python 为py3.10安装pip\n",
        "!sudo apt-get install python3.10-distutils  > /dev/null 2>&1\n",
        "!wget https://bootstrap.pypa.io/get-pip.py  > /dev/null 2>&1\n",
        "!python get-pip.py  > /dev/null 2>&1\n",
        "#install colab's dependencies 安装colab依赖\n",
        "!python -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor  > /dev/null 2>&1\n",
        "# link to the old google package 将py3.9的谷歌依赖连接至3.10\n",
        "!ln -s /usr/local/lib/python3.9/dist-packages/google \\\n",
        "/usr/local/lib/python3.10/dist-packages/google  > /dev/null 2>&1\n",
        "print(\"python升级完成 1/6\")\n",
        "\n",
        "#这是一个备份更新python3.10.6的方式\n",
        "#切换到python3.10\n",
        "#!wget https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n",
        "#!bash ./py310.sh -b -f -p /usr/local\n",
        "#!python -m ipykernel install --name \"py310\" --user\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "###################################################################################\n",
        "#安装相关环境\n",
        "\n",
        "pip_all_number = 3\n",
        "pip_count = 1\n",
        "\n",
        "#liblz4-tool需要解压才安装\n",
        "#安装aria2\n",
        "!apt -qq install aria2\n",
        "\n",
        "#安装兼容torch 2.0.0\n",
        "print(f\"torch安装中\")\n",
        "!pip -q install torch==2.0.1 torchvision xformers triton\n",
        "print(f\"torch安装完成 {pip_count}/{pip_all_number}\")\n",
        "\n",
        "#安装其他依赖\n",
        "print(f\"其他依赖安装中，此步耗时较长，请耐心等待\")\n",
        "%cd /content/lora-scripts/sd-scripts/\n",
        "!pip -q install --upgrade -r requirements.txt\n",
        "print(f\"其他依赖安装完成 {pip_count}/{pip_all_number}\")\n",
        "pip_count+=1\n",
        "\n",
        "#安装lion优化器、dadaptation优化器、lycoris\n",
        "print(f\"lion优化器、dadaptation优化器、lycoris安装中\")\n",
        "!pip -q install --upgrade lion-pytorch lycoris-lora dadaptation\n",
        "print(f\"lion优化器、lycoris安装完成 {pip_count}/{pip_all_number}\")\n",
        "pip_count+=1\n",
        "\n",
        "!python --version\n",
        "\n",
        "#############################\n",
        "#开启tensorboard\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "8Qp6STJk2Wjh",
        "collapsed": true,
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8870c7cd-a9c6-4fe3-c37b-642efced46ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "torch安装中\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htorch安装完成 1/3\n",
            "其他依赖安装中，此步耗时较长，请耐心等待\n",
            "/content/lora-scripts/sd-scripts\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "yfinance 0.2.28 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m其他依赖安装完成 1/3\n",
            "lion优化器、dadaptation优化器、lycoris安装中\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "lion优化器、lycoris安装完成 2/3\n",
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3是否使用Waifu Diffusion 1.4 Tagger V2打标(可选)"
      ],
      "metadata": {
        "id": "W9wqv5U3iVZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###5.3使用WD1.4tagger打标（原始代码来源于：[Linaqruf](https://github.com/Linaqruf/kohya-trainer)）\n",
        "#[Waifu Diffusion 1.4 Tagger V2](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags)是由[SmilingWolf](https://github.com/SmilingWolf)开发的Danbooru风格的图片分类器，可以用来生成tag\n",
        "#（例如: `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background`）\n",
        "\n",
        "#@markdown 我有一个关于图片预处理的视频推荐使用WD1.4打标，有些人和我说没有本地webui要怎么打标\n",
        "\n",
        "#@markdown 这个打标没webui里那个好，但好歹能打标对吧（可以直接对谷歌硬盘里的图片进行操作）\n",
        "\n",
        "#@markdown kohya已经编写了打标脚本，我从另一个colab（[Linaqruf](https://github.com/Linaqruf/kohya-trainer)，他有更强大的Colab lora训练，感兴趣可以去看看）里fork了这段代码\n",
        "\n",
        "#@markdown 如果你已经在本地完成了打标，可以忽略这个代码块\n",
        "\n",
        "#@markdown **是否使用WD1.4打标**\n",
        "use_tagger = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **(必填)**填入你要打标的文件夹地址，如果你有多个概念文件夹，你需要为每个都执行这项操作\n",
        "tag_data_dir = \"/content/drive/MyDrive/Lora/input/repeat_concept\" #@param {type:'string'}\n",
        "\n",
        "#@markdown batch大小、加载线程、打标模型\n",
        "batch_size = 8 #@param {type:'number'}\n",
        "max_data_loader_n_workers = 2 #@param {type:'number'}\n",
        "tagger_model = \"SmilingWolf/wd-v1-4-convnext-tagger-v2\" #@param [\"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
        "#@markdown 调整阈值，越低tag越多，但准确率越低\n",
        "#@markdown - 这两句是代码作者的原话，自己判断对不对，反正我喜欢用0.35炼人物\n",
        "#@markdown - 高阈值(例如`0.85`)适用于人物或者物体的训练\n",
        "#@markdown - 低阈值(例如`0.35`)适用于常规的\\画风的\\环境的训练\n",
        "threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "if use_tagger:\n",
        "#图片路径为谷歌邮箱中的路径\n",
        "  !python /content/lora-scripts/sd-scripts/finetune/tag_images_by_wd14_tagger.py \\\n",
        "    \"{tag_data_dir}\" \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --repo_id {tagger_model} \\\n",
        "    --thresh {threshold} \\\n",
        "    --caption_extension .txt \\\n",
        "    --max_data_loader_n_workers {max_data_loader_n_workers}\n",
        "else:\n",
        "  print(\"似乎你想使用WD1.4tagger，但你并未勾选\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "go-KBrkHQuNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 从谷歌硬盘中拷贝训练材料"
      ],
      "metadata": {
        "id": "9GeMKE6hie8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####拷贝材料(支持重复训练时选择新的路径)\n",
        "\n",
        "#@markdown 默认给的是教程（三）中的谷歌硬盘目录，你也可以自定义训练集和正则化集路径（只要你知道你在做什么）,请选择repeat_concept的父目录\n",
        "\n",
        "#@markdown 为了稳定性和性能，notebook会把材料拷贝到colab的`/content/lora-scripts/train/`中进行操作\n",
        "\n",
        "#@markdown 是否使用自定义路径，是否拷贝正则化图片\n",
        "use_data_dir_self = True #@param {type:\"boolean\"}\n",
        "copy_reg = False #@param {type:\"boolean\"}\n",
        "#@markdown 自定义训练集路径，正则化集路径（仅在勾选后有效）**（不要使用带空格、中文的路径）**\n",
        "train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\" #@param {type:'string'}\n",
        "reg_data_dir_self = \"/content/drive/MyDrive/Lora/reg/\" #@param {type:'string'}\n",
        "\n",
        "if use_data_dir_self:\n",
        "  print(f\"你使用的是自定义路径\")\n",
        "else:\n",
        "  train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\"\n",
        "  reg_data_dir_self = \"/content/drive/MyDrive/Lora/reg/\"\n",
        "  print(f\"你使用的是默认路径\")\n",
        "print(f\"训练集地址为:{train_data_dir_self}\")\n",
        "\n",
        "\n",
        "#@markdown 拷贝时间由训练材料大小决定\n",
        "\n",
        "#@markdown 出现这样的输出就是正确放置了文件且完成了拷贝\n",
        "\n",
        "#@markdown ![copy.png](data:image/png;base64,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)\n",
        "\n",
        "#删除之前的训练材料\n",
        "!mkdir -p /content/lora-scripts/train/  #防止首次运行报错\n",
        "!rm -r /content/lora-scripts/train/\n",
        "\n",
        "#从谷歌硬盘中拷贝你之前上传的训练材料\n",
        "print(\"拷贝训练集中\")\n",
        "!mkdir -p {train_data_dir}\n",
        "!cp -r {train_data_dir_self}/* {train_data_dir}\n",
        "!echo \"copy训练材料完成.\"\n",
        "\n",
        "if copy_reg:\n",
        "  #拷贝正则化图片\n",
        "  print(f\"正则化集地址为:{reg_data_dir_self}\")\n",
        "  print(\"拷贝正则化集中\")\n",
        "  !mkdir -p {reg_data_dir}\n",
        "  !cp -r {reg_data_dir_self}/* {reg_data_dir}\n",
        "  !echo \"copy正则化图片完成.\"\n",
        "else:\n",
        "  print(\"不拷贝正则化集\")\n",
        "\n",
        "\n",
        "%cd /content/lora-scripts"
      ],
      "metadata": {
        "id": "j6nkqp9Fb7Dg",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a39dbf-d3e9-4519-9c66-c72eecbd34a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你使用的是自定义路径\n",
            "训练集地址为:/content/drive/MyDrive/Lora/input/\n",
            "拷贝训练集中\n",
            "cp: cannot stat '{train_data_dir_self}/*': No such file or directory\n",
            "copy训练材料完成.\n",
            "不拷贝正则化集\n",
            "/content/lora-scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H9n6osbw7FQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##（六） 下载模型，默认选择的是novelAI官模剪枝版（原始代码来源于：[Linaqruf](https://github.com/Linaqruf/kohya-trainer)）"
      ],
      "metadata": {
        "id": "2wRUt_h0FHy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 6.1 下载模型\n",
        "installModels = []\n",
        "installv2Models = []\n",
        "\n",
        "#@markdown ####**选择优先级从上到下，比如说你想自定义链接，则需要保持两个预设模型为空**\n",
        "\n",
        "#@markdown **预设剪枝模型（`Animefull-final-pruned`即NovelAI官模 ， `Stable-Diffusion-v1-5`即SD1.5）**\n",
        "\n",
        "#@markdown SD1.x model\n",
        "modelName = \"Animefull-final-pruned\"  # @param [\"\", \"Animefull-final-pruned\", \"Stable-Diffusion-v1-5\", \"Anything-v3-1\", \"AnyLoRA\", \"AnimePastelDream\", \"Chillout-mix\", \"OpenJourney-v4\"]\n",
        "#@markdown SD2.x model\n",
        "v2ModelName = \"\"  # @param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"plat-diffusion-v1-3-1\", \"replicant-v1\", \"illuminati-diffusion-v1-0\", \"illuminati-diffusion-v1-1\", \"waifu-diffusion-1-4-anime-e2\", \"waifu-diffusion-1-5-e2\", \"waifu-diffusion-1-5-e2-aesthetic\"]\n",
        "\n",
        "#@markdown **自定义模型链接例如`https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/novelailatest-pruned.ckpt`）**\n",
        "\n",
        "#@markdown **或者自定义模型路径例如`/content/drive/MyDrive/Lora/model/your_model.ckpt`**\n",
        "\n",
        "#@markdown **如果连接或者路径中包含模型的扩展名(比如我给出的两个例如的末尾都有扩展名)，则会自动指定，否则你需要手动选择**\n",
        "\n",
        "#@markdown - **注意，Colab普通用户仅能选择5G以下的模型**\n",
        "\n",
        "base_model_url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "base_model_self_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "base_model_extension = \"ckpt\" #@param [\"ckpt\", \"safetensors\", \"pt\"]\n",
        "\n",
        "\n",
        "modelUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "    \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "    \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "]\n",
        "modelList = [\n",
        "    \"\",\n",
        "    \"Animefull-final-pruned\",\n",
        "    \"Anything-v3-1\",\n",
        "    \"AnyLoRA\",\n",
        "    \"AnimePastelDream\",\n",
        "    \"Chillout-mix\",\n",
        "    \"OpenJourney-v4\",\n",
        "    \"Stable-Diffusion-v1-5\",\n",
        "]\n",
        "v2ModelUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\",\n",
        "    \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n",
        "    \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\",\n",
        "    \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors\",\n",
        "    \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\",\n",
        "    \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n",
        "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\",\n",
        "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors\",\n",
        "    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors\",\n",
        "]\n",
        "v2ModelList = [\n",
        "    \"\",\n",
        "    \"stable-diffusion-2-1-base\",\n",
        "    \"stable-diffusion-2-1-768v\",\n",
        "    \"plat-diffusion-v1-3-1\",\n",
        "    \"replicant-v1\",\n",
        "    \"illuminati-diffusion-v1-0\",\n",
        "    \"illuminati-diffusion-v1-1\",\n",
        "    \"waifu-diffusion-1-4-anime-e2\",\n",
        "    \"waifu-diffusion-1-5-e2\",\n",
        "    \"waifu-diffusion-1-5-e2-aesthetic\",\n",
        "]\n",
        "if modelName:\n",
        "    installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "if v2ModelName:\n",
        "    installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "\n",
        "#下载路径\n",
        "base_model_dir = \"/content/lora-scripts/sd-models/\"\n",
        "\n",
        "#检查连接是否含有扩展名信息，不含有则由用户指定\n",
        "def check_ext(url):\n",
        "  if url.endswith(\".ckpt\"):\n",
        "    return \"ckpt\"\n",
        "  elif url.endswith(\".safetensors\"):\n",
        "    return \"safetensors\"\n",
        "  else:\n",
        "    return base_model_extension\n",
        "#下载模型\n",
        "def install(checkpoint_name, url):\n",
        "    ext = check_ext(url)\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {checkpoint_name}.{ext} {url}\n",
        "    return f\"{checkpoint_name}.{ext}\"   #返回模型名称\n",
        "def install_checkpoint():\n",
        "    for model in installModels:\n",
        "        return install(model[0], model[1])\n",
        "    for v2model in installv2Models:\n",
        "        return install(v2model[0], v2model[1])\n",
        "\n",
        "#尝试下载预设模型\n",
        "base_model_name = install_checkpoint()\n",
        "#预设下载成功，则完成路径修改\n",
        "if base_model_name:\n",
        "  pretrained_model = base_model_dir + base_model_name\n",
        "#下载失败，base_model_name为non\n",
        "else:\n",
        "  #不留空，则尝试用连接下载\n",
        "  if base_model_url:\n",
        "    base_model_name = \"download.\" + check_ext(base_model_url)\n",
        "    pretrained_model = base_model_dir + base_model_name\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {base_model_name} --allow-overwrite {base_model_url}\n",
        "  #留空，将考虑从自定义路径中拷贝\n",
        "  else:\n",
        "    if base_model_self_dir:\n",
        "      base_model_name = \"self.\" + check_ext(base_model_self_dir)\n",
        "      pretrained_model = base_model_dir + base_model_name\n",
        "      !cp {base_model_self_dir} {pretrained_model}\n",
        "    else:\n",
        "      print(\"你根本没选择任何模型！\")\n",
        "\n",
        "\n",
        "#修改train.sh的底模路径，并输出信息\n",
        "search_input(\"pretrained_model\", pretrained_model)\n",
        "\n",
        "#输出模型信息\n",
        "print(f\"你选择的是: {base_model_name} 模型\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BWOcwdgxDBj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 6.2 下载vae（可选）\n",
        "\n",
        "#储存下载信息参数\n",
        "installVae = []\n",
        "#@markdown 选择 `none` 意味着不使用vae\n",
        "\n",
        "#@markdown 选择一个Vae下载并使用`\"animevae.pt\", \"kl-f8-anime.ckpt\", \"vae-ft-mse-840000-ema-pruned.ckpt\"`\n",
        "\n",
        "vaeUrl = [\n",
        "    \"\",\n",
        "    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "    \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "]\n",
        "vaeList = [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"none\"  # @param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "#开始下载\n",
        "vae_dir = \"/content/lora-scripts/vae/\"\n",
        "def install(vae_name, url):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    !aria2c --console-log-level=error --allow-overwrite --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vae_dir} -o \"vae.pt\" \"{url}\"\n",
        "\n",
        "def install_vae():\n",
        "    if vaeName != \"none\":\n",
        "        for vae in installVae:\n",
        "            install(vae[0], vae[1])\n",
        "    else:\n",
        "        pass\n",
        "install_vae()\n",
        "\n",
        "\n",
        "extArgs_content.vae = \"\"\n",
        "#修改train.sh中参数\n",
        "if vaeName == \"none\":\n",
        "  print(\"不使用vae\")\n",
        "else:\n",
        "  print(f\"使用{vaeName}\")\n",
        "  #写入采样地址f\"--vae={vae_dir}\"\n",
        "  extArgs_content.vae += f\"\\\"--vae={vae_dir}vae.pt\\\" \"\n",
        "\n",
        "search_input(\"\", extArgs_content.all() )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3_29lrzlARme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##（七）修改train.sh参数\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vhwhQZEEq65p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1、你可以使用此代码块设置常用参数，也可以打开*/content/lora-scripts/train.sh*手动设置其它参数\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**2、注意，如果你手动配置参数，除非你知道你在做什么，不然不要修改底模路径和训练集图片路径**\n",
        "\n",
        "```\n",
        "pretrained_model=\"./sd-models/model.ckpt\" # base model path | 底模路径\n",
        "\n",
        "train_data_dir=\"./train/aki\" # train dataset path | 训练数据集路径\n",
        "```\n",
        "\n",
        "3、输出的模型会自动保存至你的谷歌硬盘/Lora/output/(output_folder_name)目录下\n",
        "\n",
        "如果你没有挂载谷歌硬盘，则模型会存储在Colab环境中的/content/MyDriveLora/output/(output_folder_name)这个路径下。但是请注意，一旦Colab重启会被清除，请**及时下载保存**模型。"
      ],
      "metadata": {
        "id": "cJxcHwv8Sa9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###7.1基础参数\n",
        "\n",
        "#@markdown 为了适配秋叶的train.sh内容更新，正则匹配函数现在会报错：`\"警告！！！对于'{search}'的正则表达式并未匹配，请手动设置该参数，并B站私信我更新！\"`\n",
        "\n",
        "#@markdown 看到这个提示你可以手动修改train.sh中相关部分，也可以使用WSH的库，也可也B站私信我更新notebook\n",
        "\n",
        "\n",
        "#用于修改train.sh文件\n",
        "extArgs_content.common_parameter = \"\"\n",
        "\n",
        "#底模信息\n",
        "#print(\"你选择的是\" + base_model + \"底模\")\n",
        "#print(\"格式为\" + base_model_extension)\n",
        "\n",
        "\n",
        "#@markdown 是否使用正则化、正则化权重（越小越不正则）\n",
        "use_reg_data = True #@param {type:\"boolean\"}\n",
        "if use_reg_data:\n",
        "  search_input(\"reg_data_dir\", \"reg_data_dir\")\n",
        "  print(\"\\b使用正则化\")\n",
        "else:\n",
        "  search_input(\"reg_data_dir\", \"\")\n",
        "  print(\"\\b不使用正则化\")\n",
        "prior_loss_weight = 0.3 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "search_input(\"  --prior_loss_weight\", prior_loss_weight)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown 输出模型命名、格式(模型会被输出至`{output_folder_dir}/{output_name}；默认为：/content/drive/MyDrive/Lora/output/output_name`)\n",
        "output_name = \"tom1111\" #@param {type:\"string\"}\n",
        "search_input(\"output_name\", output_name)\n",
        "save_model_as = \"safetensors\" #@param [\"ckpt\", \"safetensors\", \"pt\"]\n",
        "search_input(\"save_model_as\", save_model_as)\n",
        "output_folder_dir = \"/content/drive/MyDrive/Lora/output\" #@param {type:\"string\"}\n",
        "#保存模型至同名文件夹\n",
        "#output_dir在4.2中被初始化\n",
        "output_dir = output_folder_dir + \"/\" + output_name\n",
        "search_input(\"  --output_dir\", output_dir)\n",
        "#修改log输出至谷歌硬盘\n",
        "#logging_dir在4.2中初始化\n",
        "logging_dir = output_dir + \"/logs\"\n",
        "search_input(\"  --logging_dir\", logging_dir)\n",
        "print(f\"模型输出地址为：{output_dir}\")\n",
        "print(f\"log文件将会被保存至:{logging_dir}\")\n",
        "\n",
        "\n",
        "#@markdown 图片分辨率:\"宽,高\"。支持非正方形（必须是64的倍数）\n",
        "width = 512 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
        "height = 768 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
        "resolution = f\"{width},{height}\"\n",
        "search_input(\"resolution\", resolution)\n",
        "\n",
        "#@markdown batch大小（colab普通用户512*768最多只能选5，超过就会爆显存，你可以试试）\n",
        "batch_size = 1 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "search_input(\"batch_size\", batch_size)\n",
        "\n",
        "#@markdown 优化器选择 `一般用前三个就行\"`\n",
        "optimizer_type = \"AdamW8bit\" #@param [\"AdamW8bit\", \"Lion\", \"DAdaptation\", \"AdamW\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
        "search_input(\"optimizer_type\", optimizer_type)\n",
        "\n",
        "#@markdown unet学习率与text学习率（lr将被设置为等于unet_lr）\n",
        "#@markdown `DAdaptation优化器的学习率会自动调整，通常指定unet_lr=1;如果你希望text_encoder_lr为unet_lr一半，则指定text_encoder_lr=0.5`\n",
        "unet_lr = \"1.5e-4\" #@param {type:\"string\"}\n",
        "search_input(\"lr\", unet_lr)\n",
        "search_input(\"unet_lr\", unet_lr)\n",
        "text_encoder_lr = \"1e-5\" #@param {type:\"string\"}\n",
        "search_input(\"text_encoder_lr\", text_encoder_lr)\n",
        "\n",
        "#@markdown network dim与alpah\n",
        "network_dim = 32 #@param {type:\"number\"}\n",
        "search_input(\"network_dim\", network_dim)\n",
        "network_alpha = 16 #@param {type:\"number\"}\n",
        "search_input(\"network_alpha\", network_alpha)\n",
        "\n",
        "#@markdown 最大训练epoch ; 每N个epoch 保存一次\n",
        "max_train_epoches = 15 #@param {type:\"number\"}\n",
        "search_input(\"max_train_epoches\", max_train_epoches)\n",
        "save_every_n_epochs = 1 #@param {type:\"number\"}\n",
        "search_input(\"save_every_n_epochs\", save_every_n_epochs)\n",
        "\n",
        "#@markdown 噪声偏移、保留前N个token顺序不变、伽马射线事件的最小信噪比`开启推荐为5`\n",
        "noise_offset = 0.05 #@param {type:\"number\"}\n",
        "search_input(\"noise_offset\", f\"{noise_offset}\")\n",
        "keep_tokens = 1 #@param {type:\"number\"}\n",
        "search_input(\"keep_tokens\", keep_tokens)\n",
        "min_snr_gamma = 0 #@param {type:\"number\"}\n",
        "search_input(\"min_snr_gamma\", min_snr_gamma)\n",
        "\n",
        "#@markdown 学习率调度器、升温步数、余弦硬重启次数 ； 升温步数建议设置成总steps的5%左右`总steps = epoch * repeat * (训练集+正则图数） / batch`不会算就跑一遍训练看看\n",
        "lr_scheduler = \"cosine_with_restarts\" #@param [\"cosine_with_restarts\",\"cosine\",\"polynomial\",\"linear\",\"constant_with_warmup\",\"constant\"]\n",
        "search_input(\"lr_scheduler\", lr_scheduler)\n",
        "lr_warmup_steps = 0 #@param {type:\"number\"}\n",
        "search_input(\"lr_warmup_steps\", lr_warmup_steps)\n",
        "lr_restart_cycles = 1 #@param {type:\"number\"}\n",
        "search_input(\"lr_restart_cycles\", lr_restart_cycles)\n",
        "\n",
        "#@markdown 训练方法`\"LoRa\", \"LoCon\", \"LoHa\"`\n",
        "train_method = \"LoRa\" #@param [\"LoRa\", \"LoCon\", \"LoHa\"]\n",
        "if train_method == \"LoRa\":\n",
        "  network_module = \"networks.lora\"\n",
        "  algo = \"lora\"\n",
        "elif train_method == \"LoCon\":\n",
        "  network_module = \"lycoris.kohya\"\n",
        "  algo = \"lora\"\n",
        "elif train_method == \"LoHa\":\n",
        "  network_module = \"lycoris.kohya\"\n",
        "  algo = \"loha\"\n",
        "else:\n",
        "  print(\"训练方法选择出错\")\n",
        "search_input(\"network_module\", network_module)\n",
        "search_input(\"algo\", algo)\n",
        "print(f\"{train_method}训练方法\")\n",
        "\n",
        "#@markdown locon训练的dim与alpha（仅在\"LoCon\"、\"LoHa\"训练方法时有效）\n",
        "conv_dim = 8 #@param {type:\"number\"}\n",
        "search_input(\"conv_dim\", conv_dim)\n",
        "conv_alpha = 4 #@param {type:\"number\"}\n",
        "search_input(\"conv_alpha\", conv_alpha)\n",
        "\n",
        "#@markdown 对于SD2模型(这个是底模为SD2训练时候使用的，不懂就不要选)\n",
        "is_v2_model = False #@param {type:\"boolean\"}\n",
        "search_input(\"is_v2_model\", 1 if is_v2_model else 0)\n",
        "parameterization = False #@param {type:\"boolean\"}\n",
        "search_input(\"parameterization\", 1 if parameterization else 0)\n",
        "\n",
        "if is_v2_model:\n",
        "  print(\"启动SD2.0模型设置\")\n",
        "if parameterization:\n",
        "  print(\"启动parameterization参数化\")\n",
        "\n",
        "\n",
        "#@markdown lowram模式(用显存来补充内存)\n",
        "lowram = False #@param {type:\"boolean\"}\n",
        "if lowram:\n",
        "  #写入\"--lowram\"\n",
        "  extArgs_content.common_parameter += \"\\\"--lowram\\\" \"\n",
        "  print(\"启动--lowram\")\n",
        "\n",
        "\n",
        "search_input(\"\", extArgs_content.all() )\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NDHiaHc4qWHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2有趣的边训练边出图（可选）"
      ],
      "metadata": {
        "id": "19nEZDbHMzsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####采样图片参数设置,输出图片位置与模型输出文件夹一致（原始代码来源于：[Linaqruf](https://github.com/Linaqruf/kohya-trainer)）\n",
        "#@markdown 支持使用`(1girl:1.1)`和`[1girl]`格式，不限数量的tag\n",
        "\n",
        "#@markdown 你要是懂怎么用，你也可以运行后修改这个采样参数文件`/content/lora-scripts/sample_prompt.txt`\n",
        "\n",
        "#用于修改train.sh中extArgs数组的内容\n",
        "extArgs_content.sample_parameter = \"\"\n",
        "\n",
        "#4.2中被定义,8.2中也会被使用\n",
        "enable_sample = True #@param {type:\"boolean\"}\n",
        "#@markdown 采样间隔（每n个step/epoch采样，n=）\n",
        "sample_every_n_type = \"sample_every_n_epochs\" #@param [\"sample_every_n_steps\", \"sample_every_n_epochs\"]\n",
        "sample_every_n_type_value = 1 #@param {type:\"number\"}\n",
        "#@markdown 采样参数（采样器、正面tag、负面、宽、高、scale、种子、采样步数）\n",
        "sampler = \"euler_a\" #@param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "prompt = \"(masterpiece, best quality, hi-res:1.2), 1girl, solo\" #@param {type: \"string\"}\n",
        "negative = \"(worst quality, bad quality:1.4), lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type:\"string\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "height = 768 #@param {type:\"number\"}\n",
        "scale = 7 #@param {type:\"number\"}\n",
        "seed = -1 #@param {type:\"number\"}\n",
        "steps = 28 #@param {type:\"number\"}\n",
        "\n",
        "#配置采样参数\n",
        "sample_str = f\"\"\"\n",
        "  {prompt} \\\n",
        "  --n {negative} \\\n",
        "  --w {width} \\\n",
        "  --h {height} \\\n",
        "  --l {scale} \\\n",
        "  --s {steps} \\\n",
        "  {f\"--d \" + f\"{seed}\" if seed > 0 else \"\"} \\\n",
        "\"\"\"\n",
        "\n",
        "if enable_sample:\n",
        "  #生成采样参数文件\n",
        "  with open(sample_prompt_txt_path, \"w\") as f:\n",
        "    f.write(sample_str)\n",
        "  #写入采样地址\"--sample_prompts={sample_prompt_txt_path}\"\n",
        "  extArgs_content.sample_parameter += f\"\\\"--sample_prompts={sample_prompt_txt_path}\\\" \"\n",
        "  #\"--sample_sampler=euler_a\"\n",
        "  extArgs_content.sample_parameter += f\"\\\"--sample_sampler={sampler}\\\" \"\n",
        "  #写入采样间隔\"--sample_every_n_epochs=1\"\n",
        "  if sample_every_n_type == \"sample_every_n_epochs\":\n",
        "    extArgs_content.sample_parameter += f\"\\\"--sample_every_n_epochs={sample_every_n_type_value}\\\" \"\n",
        "  elif sample_every_n_type == \"sample_every_n_steps\":\n",
        "    extArgs_content.sample_parameter += f\"\\\"--sample_every_n_steps={sample_every_n_type_value}\\\" \"\n",
        "  else:\n",
        "    print(\"采样间隔参数出错\")\n",
        "  print(f\"启用采样功能\")\n",
        "else:\n",
        "  print(f\"不使用采样功能\")\n",
        "\n",
        "\n",
        "#写入trian.sh\n",
        "search_input(\"\", extArgs_content.all() )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H3kSAQXnM8sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3进阶参数"
      ],
      "metadata": {
        "id": "g8uAVOwb4wd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####设置进阶参数\n",
        "\n",
        "#用于暂存要修改至extArgs的内容\n",
        "extArgs_content.plus_parameter = \"\"\n",
        "\n",
        "#@markdown 从训练好的lora模型上继续训练，填写模型地址，如`/content/drive/MyDrive/Lora/output/output_name.safetensors`,留空则不启用该功能\n",
        "\n",
        "#@markdown 从学习状态上继续训练，填写学习状态文件夹地址，如`/content/drive/MyDrive/Lora/output/ouput_name-n-state`,留空我不知道会怎么样\n",
        "\n",
        "use_retrain = \"no\" #@param [\"no\",\"model\",\"state\"]\n",
        "retrain_dir = \"/content/drive/MyDrive/Lora/output\" #@param {type:\"string\"}\n",
        "\n",
        "if use_retrain == \"no\":\n",
        "  search_input(\"network_weights\", \"\")\n",
        "  search_input(\"resume\", \"\")\n",
        "  print(\"不使用重训练\")\n",
        "elif use_retrain == \"model\":\n",
        "  search_input(\"network_weights\", retrain_dir)\n",
        "  search_input(\"resume\", \"\")\n",
        "  print(\"从预先训练的lora模型上继续训练\")\n",
        "elif use_retrain == \"state\":\n",
        "  search_input(\"network_weights\", \"\")\n",
        "  search_input(\"resume\", retrain_dir)\n",
        "  print(\"从上次的学习状态继续训练\")\n",
        "\n",
        "\n",
        "#@markdown 保存epoch模型的同时保存学习状态（包括优化器状态，8.1中tensorboard查看）,方便更加精确的断点训练，**注意每个状态文件夹有5g**，建议高repeat低epoch长时间训练时使用（colab最多只能连续4小时）\n",
        "save_state = False #@param {type:\"boolean\"}\n",
        "search_input(\"save_state\", 1 if save_state else 0)\n",
        "print( (\"\"if save_state else \"不\") + \"保存学习状态\")\n",
        "\n",
        "#@markdown 桶最小、大分辨率\n",
        "min_bucket_reso = 256 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
        "search_input(\"min_bucket_reso\", min_bucket_reso)\n",
        "max_bucket_reso = 1024 #@param {type:\"slider\", min:64, max:1920, step:64}\n",
        "search_input(\"max_bucket_reso\", max_bucket_reso)\n",
        "\n",
        "#@markdown 跳过层\n",
        "clip_skip = 2 #@param {type:\"slider\", min:1, max:2, step:1}\n",
        "search_input(\"clip_skip\", clip_skip)\n",
        "\n",
        "#@markdown 标签文件扩展名\n",
        "caption_extension = \"txt\" #@param {type:\"string\"}\n",
        "caption_extension = \".\" + caption_extension\n",
        "search_input(\"  --caption_extension\", caption_extension)\n",
        "\n",
        "#@markdown 训练最大token数\n",
        "max_token_length = 225 #@param {type:\"slider\", min:75, max:225, step:75}\n",
        "search_input(\"  --max_token_length\", max_token_length)\n",
        "\n",
        "\n",
        "#@markdown 种子\n",
        "seed = \"1337\" #@param {type:\"string\"}\n",
        "search_input(\"  --seed\", seed)\n",
        "\n",
        "\n",
        "#写入train.sh\n",
        "search_input(\"\", extArgs_content.all() )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ormmXEOn4zCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4使用预先保存的配置文件进行覆盖（可选）"
      ],
      "metadata": {
        "id": "AyqSNCvqO1OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### 覆盖配置文件\n",
        "#@markdown 是否使用预先保存的trian.sh覆盖默认参数文件(导入自定义的train.sh并不会更新7中的参数，所以导入后如果你想修改，直接打开`/content/lora-scripts/train.sh`手动改)\n",
        "use_train_sh_self = False #@param {type:\"boolean\"}\n",
        "train_sh_self_path = \"/content/drive/MyDrive/Lora/output/output_name/train.sh\" #@param {type:\"string\"}\n",
        "\n",
        "if use_train_sh_self:\n",
        "  print(f\"使用预先保存的trian.sh， {train_sh_self_path}将覆盖{train_sh_path}\")\n",
        "  !cp {train_sh_self_path} {train_sh_path}\n",
        "else:\n",
        "  print(f\"使用默认路径的train.sh：{train_sh_path}\")\n",
        "\n",
        "#@markdown 如果预先保存的train.sh中启用了采样功能，请启用并填入预先保存的采样参数文件路径\n",
        "use_sample_prompt_txt_self = False #@param {type:\"boolean\"}\n",
        "sample_prompt_txt_self_path = \"/content/drive/MyDrive/Lora/output/output_name/sample_prompt.txt\" #@param {type:\"string\"}\n",
        "\n",
        "if use_sample_prompt_txt_self:\n",
        "  print(f\"使用预先保存的sample_prompt.txt， {sample_prompt_txt_self_path}将覆盖{sample_prompt_txt_path}\")\n",
        "  !cp {sample_prompt_txt_self_path} {sample_prompt_txt_path}\n",
        "else:\n",
        "  print(f\"你选择了：预先保存的train.sh中不启用采样\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MmNiZhUMog__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##（八）开始训练 😀"
      ],
      "metadata": {
        "id": "kqddLa2TFY2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###8.1是否使用tensorboard ：loss与学习率可视化工具（可选）\n",
        "#@markdown 你可以在训练前启动它，当训练开始过一会出现loss后，右上角刷新就可以实时监控loss和学习率 ； 训练开始后，如果你没启动的话，就只能在训练**结束**后启动\n",
        "\n",
        "use_tensorboard = True #@param {type:\"boolean\"}\n",
        "#@markdown 是否使用自定义的log日志路径:`留空则指定为当前train.sh中指定的log日志路径`\n",
        "logging_dir_self = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 如果提示端口被占用，就换个端口\n",
        "port = \"8008\" #@param {type:\"string\"}\n",
        "\n",
        "if use_tensorboard:\n",
        "  #指定tensorboard的读取路径\n",
        "  if logging_dir_self:\n",
        "    tensorboard_log_dir = logging_dir_self\n",
        "    print(f\"你指定了自定义的log日志路径：{tensorboard_log_dir}\")\n",
        "  else:\n",
        "    tensorboard_log_dir = search_get(\"  --logging_dir\")\n",
        "    print(f\"采用trian.sh中指定的log日志路径：{tensorboard_log_dir}\")\n",
        "  %tensorboard --logdir={tensorboard_log_dir} --port={port}\n",
        "else:\n",
        "  print(\"你似乎想使用tensorboard，但并未勾选该选项\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "498HAF6rwU_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  ### 8.2开始训练\n",
        "#@markdown 若正确运行，训练完成后，模型会自动保存至你的谷歌硬盘中`我的云端硬盘/Lora/output/`\n",
        "\n",
        "#@markdown 如果不到1分钟就运行完了，多半是出错了，把输出信息复制到ChatGPT问下罢！ :(\n",
        "\n",
        "#@markdown - Q：输出代码的最后出现（kill:9）字样\n",
        "\n",
        "#@markdown - A：爆ram了，更换小的底模\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown 是否保存本次训练的train.sh和采样配置（如果你启用采样功能的话）\n",
        "\n",
        "#@markdown 保存路径： `留空则保存至当前train.sh中指定的输出路径`\n",
        "save_files = True #@param {type:\"boolean\"}\n",
        "save_files_dir_self = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if save_files:\n",
        "  #指定保存路径\n",
        "  if save_files_dir_self:\n",
        "    save_files_dir = save_files_dir_self\n",
        "    print(f\"你指定了自定义的配置保存路径：{save_files_dir}\")\n",
        "  else:\n",
        "    save_files_dir = search_get(\"  --output_dir\")\n",
        "    print(f\"采用trian.sh中指定的输出路径：{save_files_dir}\")\n",
        "  #保存训练参数文件至谷歌硬盘\n",
        "  !mkdir -p {save_files_dir}\n",
        "  !cp {train_sh_path} {save_files_dir}\n",
        "  print(f\"训练参数被保存至{save_files_dir}\")\n",
        "  #保存采样参数文件至谷歌硬盘\n",
        "  if enable_sample or use_sample_prompt_txt_self:\n",
        "    !cp {sample_prompt_txt_path} {save_files_dir}\n",
        "    print(f\"采样参数被保存至{save_files_dir}\")\n",
        "  else:\n",
        "    print(f\"未启用采样功能，不保存采样配置\")\n",
        "else:\n",
        "  print(f\"不保存配置文件\")\n",
        "\n",
        "#开始训练！\n",
        "%cd /content/lora-scripts/\n",
        "!bash train.sh\n",
        "\n",
        "!echo \"完成了 XXXD.\""
      ],
      "metadata": {
        "id": "ZXFX2-C_Z-9N",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3挂机代码（复制到浏览器控制台中使用,稍后添加图文指导）"
      ],
      "metadata": {
        "id": "EP59EDzIH3AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function ConnectButton() {\n",
        "  console.log(\"Connect pushed\");\n",
        "  document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "}\n",
        "// 每一分钟自动点一次按钮\n",
        "var connectInterval = setInterval(ConnectButton, 60 * 1000);\n",
        "\n",
        "// 停止自动点击按钮的定时器\n",
        "setTimeout(function() {\n",
        "  clearInterval(connectInterval);\n",
        "  console.log(\"Auto-connect stopped.\");\n",
        "}, 5 * 60 * 1000);  // 5 分钟后停止自动点击按钮"
      ],
      "metadata": {
        "id": "QpTO8eQkH7QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **D.开发者备用下载代码**"
      ],
      "metadata": {
        "id": "GQ7GziwME6Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###6.1 下载模型\n",
        "#@markdown 秋叶不推荐使用混合模型做为底模，因此默认选择了*animefull-latest-pruned*和*SD1.5（剪枝）*做为底模:\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown 选择好模型后，将连接和模型格式填入下边相应的输入框,然后运行代码块。会自动更改train.sh中底模路径\n",
        "\n",
        "#@markdown **注意！！千万不能选择过大的模型，如Anything-v4.5原版7G，会直接爆系统ram** \\\n",
        "#@markdown **5G以下应该没问题** \\\n",
        "\n",
        "#@markdown ---\n",
        "#你也可以将连接替换成你喜欢模型的直接连接，或者用git，又或者先上传到自己的谷歌硬盘再使用!cp命令拷贝到底模目录\n",
        "#@markdown **选择预设模型，或者自己下载**\n",
        "base_model = \"NovelAI\" #@param [\"NovelAI\", \"SD1.5\", \"Download by you\"]\n",
        "\n",
        "#@markdown **模型链接、模型的后缀名（例如:ckpt或safetensors）；仅在选择Download by you时有效**\n",
        "base_model_url = \"\" #@param {type:\"string\"}\n",
        "base_model_extension = \"ckpt\" #@param [\"ckpt\", \"safetensors\", \"pt\"]\n",
        "\n",
        "#选择模型\n",
        "if base_model == \"NovelAI\":\n",
        "  #base_model_url = \"https://huggingface.co/a1079602570/animefull-final-pruned/resolve/main/novelailatest-pruned.ckpt\"\n",
        "  base_model_url = \"https://huggingface.co/LarryAIDraw/animefull-final-pruned/resolve/main/animefull-final-pruned.ckpt\"\n",
        "  base_model_extension = \"ckpt\"\n",
        "elif base_model == \"SD1.5\":\n",
        "  #base_model_url = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"\n",
        "  base_model_url = \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\"\n",
        "  base_model_extension = \"ckpt\"\n",
        "elif base_model == \"Download by you\":\n",
        "  pass\n",
        "else:\n",
        "  print(\"选择模型出错\")\n",
        "\n",
        "#下载路径\n",
        "base_model_dir = \"/content/lora-scripts/sd-models/\"\n",
        "#重命名下载的模型\n",
        "base_model_name = \"model.\" + base_model_extension\n",
        "#底模路径\n",
        "pretrained_model = base_model_dir + base_model_name\n",
        "\n",
        "#6线程下载，覆盖重名\n",
        "!aria2c --console-log-level=error -s 6 -x 10 -d {base_model_dir} -o $base_model_name --allow-overwrite $base_model_url\n",
        "!echo \"下载完成\"\n",
        "\n",
        "#输出模型信息\n",
        "print(\"你选择的是\" + base_model + \"底模\")\n",
        "#修改train.sh的底模路径，并输出信息\n",
        "search_input(\"pretrained_model\", pretrained_model)\n",
        "print(\"\\b底模格式为\" + base_model_extension)"
      ],
      "metadata": {
        "id": "5xKHfJnwdXqS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}